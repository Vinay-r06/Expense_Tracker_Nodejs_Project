depolyment to production :

--preparing for depolyment
--depolymentsteps and config
--security


preparing the code for production..

--use environment varaiables--(like api keys, port numbers, passwords)---> avoid hard-coded values in u r code..
--use production API keys--(like razropay api key now used as test api keys for production api key will be depend upon third party -razropay)-->dont use that testing razropay api key
--reduce error output details--(when error happens should contain less information, users should not get our source code..)-->dont send sensitive info to yours users.. here we had default error code..u should create u r own error object..
--set secure response headers(u r application sends response)
-- add assest compression--(serving from assests like from javasacript,css files.)---reduce response size and also time...clent has to download less...modern browser are able to compress assest..
-- configure logging---(aware of whats happening in the server)--stay up to date about whats happening...
--use  SSL/TLS--()-->encrypt data in transit..we using testing was normal http server,our communication to the server was not encrypted--



below three will be often handled by the hosting provider:

add assest compression
configure logging
use  SSL/TLS


environment variables 

environment variables: are concepts supports by nodejs where we can pass certain configuaration, certain values into our node application from outside..the value will be injected when node server starts..

helmet-- this package will add certain headers to the response as u send back..
install -- npm install --save helmet..
u can use this as a middleware...then it will run on all the incoming request..
add helment in app.js
and place app.use after all middleware
run---npm run start:dev  ----new script i added to the  with nodemon..
excute and see the headers were added extra....added special headers are showing


compressing assests...

expressjs compress..middleware package...

install compression--- "npm install --save compression "

after install...go to appjs..import compression...

this will reduce size of lot javascript and css file...for the users...
image file will be not compression..that actually makes longer to load that..
here expense tracker will not required compress because it is server side rendering...


setting up request logging...

install --npm install --save morgan

use in that middleware..and assign argument...which data that u logged..how its formated..
after excute u will fing loggind data from console...we dont want in console...we store in file..
add node core module..."fs"
by this u will know wats going on the server..




deploying it--task


vt-9

setting up a ssl server..

before swifting to hositing provider..

this ssl and tls both are securing u r data that is sent from client to the server..

client<---data---> server 

data will be exchange when communicate btw client..
secure with ssl/tls encryption..
now secure because the data is unreadble as long as transit to decrypt on the server

to encrypt and decrypt--we use ---public and private key which is known to the server..

public key not something we want to protect
private key only known by the server..because private will later import for decrypting data..

the public key is used for encrypting..

in ssl certificate we binds key to identity<----public key
identity means ..domain, admin email address... u set that data when u certificate

ssl certificate connects public key to the server and sends that to the client(browser)

so, the client aware of public key and knowns that belongs to this server.
typical  some had certificate had trust browser..

but when we create certificate browser will not trust u..so in production use only trust known certificate that browser trust of quality ssl certificate for secure..
now client can encrypt the data which is sends through the server..
server can decrpt the data with that private key..only that private key can decrpt that data(which is sending)..


to create own ssl :

search browser--> openssl windows..
select binaries-opensslwiki
select first url(proweb)---openssl for windows in table
select 1 or 2 version ...

open vs code:

in terminal:

openssl req -nodes -new -x509 -keyout server.key -out server.cert
and answer all the valid answer..
commaon name: should "localhost"...different name certificate will not work ..because this has to set to u r domain...if u want run in example.com...it should example.com......use domain name which u r app is running on.
above command give u private key and public key pacakge stuff in certificate..

will get 2 
server.cert--> certificate will send to the client at the end..
server.key--> it is always stay in the server

code in app.js

const https=require('https');

const privateKey=fs.readFileSync('server.key');          // this will block code excuetion untill file it reads..to start the server it should read first..
const certificate=fs.readFileSync('server.cert');

app.listen---->change-->https.createServer({key:privateKey,cert:certificate},app).listen(process.env.PORT||3000);
now we will listen on this server..
excute--> npm start




vt-using a hositing provider..



heroku->hositing provider..
we build our own by computer with internet and expose of port number and running on u r computer and if not scalable application u nees other computer ..better use hosting provider..


virtual server/ managed space<-----------your code            ------>yours users


they will give "managed servers"(ssl,compression,logging, load balancing)


load balancing--> when u had multiple virtual server, u need more resources, incoming request will be take which had capacity to in efficent way..--> this all managed by  "managed servers"---that will visible and hosting provider will do..

this all run in "private network"(no extenal access)



diagram:


                |---private network..no external access--------------|                                                
                              
   your code---> virtual server/managed space  --><-- managed servers-->gateway, public server ---><---your users
                                                       |
                                                       ssl, compress, logging, load balancing--|





vt12--task---understanding the project and the git setup...

git--version control..

save and manage u r source code: (3 mainly feauture) commits, branches, remote repositories..


commits:

"snapshots" of u r code..
easily switch btw commits..
create commit after bugfixes, new feautures...


branches:

different "versions" of u r code..
e.g: master (production)...development, new -feature..
separate development of new feautures and bugfixing..



remote repositories:

store code + commits + branches in the cloud.
protect against loss of local data.
deploy code automatically..





vt13--task---a deployment example with heroku...
cll- command line interface..

compress will not provide by heroko..

                                           add engine task 


disable serverkey, server.cert
config u r database information in heroko config..
attach static ip in mongo db..
dymno is virtual server..
once restart server(dynomo) it will start interact by our application by remotly before we interact by locally..it will automatically serverd by https..


.gitignore...

this will tell git which floder which shoyuld not include in its snapshot..
there node_module floder is imp..all u r third party packages stored there..we wont depoly that..
that will increase the data that will transmit over the while..
instaed this nodemodules will recreated on herokoo or hosting provider..will install u r dependenace on the server after u deploy the code..
because in pacakge.json we had list of all the third party packages we using...
this will take the hosting provider and install all the by hosting provider on the server...that is y we always do-- npm install --save
because that will add all the entries in package.json file which can use during deployment..




vt15...deploying APIs...

graphl and rest







task 22--deploy to aws with cicd pipelines...

vt-1...Step 1 What is a server, AWS and Signing up..



aws, azure, and google cloud platform..

all three will give server for rent  ..


what is server?
 - like u r laptop..this had os like mac or windows, microsoft..and has proper gui system...
gui-grapichal user interface..with the help gui we can use open file anything....
this gui is like open file anything for normal user but not for techies..

in server it is made for 1 service only...servering code..it has terminal..u can use it as a laptop alsoo..
purpose of server is run the backend..when the rquest comes it serves it..


--like u r laptop- without GUI..
--linux OS or ubuntu OS..
-- it just has a terminal(when login into server) where u can run u r code...
--we can open ports of servers(get inside over the ports)..(configured from aws)..u open ports to  use external users..
-- localhost:3000..if i know serverip...serverip:3000...then i get data from backend...we want open the port 300 from the server(can do aws website)..




vt-2...Step 1.5 - High Level Planning the steps for deploying application to AWS...


-- signed up on aws- credit/ debit card..
--aws free tier..
--backend ready- move all the secrets to the .env file..
--aws--u have to go buy a server..
--configuring u r server(
    install node,
    sql server,
    git
)
--get your code from github, clone it..
--run the backend..
-- we would try to test it now..





vt-3...Step - 2 Buying and Launching your first EC2 instance....




-- signed up on aws- credit/ debit card..
--aws free tier..
--backend ready- move all the secrets to the .env file..
--aws--u have to go buy a server..                                     --doing now this..
--configuring u r server(
    install node,
    sql server,
    git
)

--running u r sql server on a different server..
--get your code from github, clone it..
--run the backend..
-- we would try to test it now..

http://serverip:3000/user/getexpenses

database would be in a different -> no access via localhost server..

http://serverip




--aws--u have to go buy a server..                                     --doing now this..




vcpu -- is like virtual cpu - 1...which is like dual core, quad core...
if vcpu is 2 means...u can do multiple like multi threading....

storage...hard disk
ssd- is solid state drive...it is very fast

// if u want to open all the ports u will go to each and indiviually and open the ports...instead of the we open security by put this ec2...security group..

security group-- all the the ec2 instance which belongs to this security group will open their ports 
4 ec2 instances--> want to allow all the ports to be opened...    


security grp 2...

2 ec2 -> only few ports to be available...example: only ports -3000 to be available...this only few ports will keep in separte security grp..to open few..

enable ssh and get port number number to enter
request come from anywhere available to entire world--0.0.0.00

create new key pair...
u will get private(u stores) and public key(servers stores)....

.pem file-- secret file...




vt-4...Step 3 - Making the Backend Ready for deployment


move all hard coded to .env file....



vt-5...Step 2.5 Connecting to the newly bought Server




--configuring u r server(                               --doing now this..
    install node,   
    sql server,
    git
)

get inside server...
cmd- get inside aws credential..
check u r in aws credential..
open that file...u will get .pem file...
open that file..it has private key..rsa privaye key..

ex: if i want get inside the laptop i want specify ip address...ip address is for locating the thing..

address  
    ipaddress

user name-----nodejspractice

go to aws root user...ec2-instances- connect-
check ssh(like travel in which to get inside u r laptop) cilent..


whenever u fire ec2 instance..ipadddress will given name 

with ip address...--
 ssh...copy till @ in ssh cilent in aws..
 and copy ip address

 run chmod(read permission) to open..if it not open..
 sudo chmod 400 filename..
 enter password...

 run --ssh -i file name ec2-user@0.0054...

steps to enter...
through public ip...

 cd file path aws credential..
 open file folder...
 ssh -i  "filename" ec2-user@3.84.55.6




in aws ssh... 

ssh -i "file name" ec2-user@domain name server(which had been created for this server)


wheneveru hitting any url(filpkart.com)..
u essential calling some server..which is running on ip address

https://www.flipkart.com-->running on a server

10.10.12.14--> https://www.flipkart.com(whenever u hit this it will hit 10.10.12.14 )

in the same... ssh -i "file name" ec2-user@domain name server

domain name server will hit ip address of ec2 instance(public ip address)

pwd(present working directory)

yum -pacakge..




vt-6...Step 4 & 5 - Configuring your server, Installing Git , node and cloning the package


install---nodejs

sudo su
curl --silent --location https://rpm.nodesource.com/setup_14.x | bash -
sudo yum install -y nodejs

install---github

sudo yum install git -y

check--- node -v
      npm -v
      git --version




get the code from git...



git clone ... contiuned after git push


vs code   --> push the backend..
click git tree..

push--- app.js, .env, database.js
message-- private keys moved to env..and click tick 
create new branch in terminal--- git checkout -b backendreadytodeploy
                            -- git push origin backendreadytodeploy

open github...new branch will uploaded...
code button click ---> copy https                           


go to terminal of ec2 

git clone paste copied link
run "ls"(find what is inside the directiry)
cd filename
ls  (it will show all the file like...app.js, middleware, package.json, models,  routers, util, controller)


start with  . is private files...

run -    ls-la    ...gives all the files..


npm start
error

npm i
error



mkdir newwork     (will create new file)
ls
new file will visible..

rm -rf newwork
ls
file is removed

sudo npm i
npm start
sequelize connection error..





vt-7...Step 6 & 7 Configuring the SQL server & Connecting RDS to EC2 instance




localhost:3306
not ruuning database from the same server... 
running in the same ec2 instance sql will be some security issues cant run...

ec2 instance -> we would be opening a few ports for http request..
(separte)sql server--> fast
regular backup of data..


aws -->RDS
create database- click

standard create
mysql
free tier

disable auto scaling
                                                (room ec2 running and db only)
public access-> no

create new security grp:
to connect database (to open the one port and connect to ec2)
we will attach this security grp to db..

name :dbsecuritygroup
  
  create database--- click..



  the database is up on a different server..
      --public ip--entire world..
      -- private ip-- internal  to aws..

            EC2 with database ( no public ip)

            address
            username   (which u created when creating db in aws)
            password   (which u created when creating db in aws)
            i should allow the ec2 instance to get inside DB..



sg of ec2 to connect sg of db:


vpc security groups select...(i am opening port to connect ec2 instance)
inbound rule .....select edit inbound
select --mysql and 3306 default...select security group of ec2 instance...
save rules



now i want change username and password..

in ec2 terminal---
git branch -a
git checkout (select u r floder)
vi .env
change the db host:  paste endpoint which is in aws...


now git clone ...we want code...

clone by https



in aws terminal
-- git clone "paste clone by https"(https://github.com/Vinay-r06/Expense_Tracker_Nodejs_Project.git)
-- ls
-- cd "floder name"/
--- ls
--- ls -la            
--- sudo npm i
--- npm start     (it works but sequelize error)
--- vi .env
--- git branch -a
-- git checkout "(file name)"
--vi .env
-- i
-- paste endpoint.. in aws rds copy endpoint



vt-8...Step 7& 8 Connecting EC2 to DB server, MYSQL workbench to DB server & Integrating with frontend


status now:
 ec2 connected to the db server..
 we can get inside ec2 instance from our laptop via ssh..



-- signed up on aws- credit/ debit card..
--aws free tier..
--backend ready- move all the secrets to the .env file..
--aws--u have to go buy a server..                                     --doing now this..
--configuring u r server(
    install node,
    sql server,
    git
)
-- get u r code from github , clone it..
--running u r sql server on a different server..
--EC2 connected successfully to sql server..
--mysql workbench also connected to the DB..
--run the backend and opened the port 3000
-- we would try to test it now from the frontend....

http://serverip:3000/user/getexpenses

database would be in a different -> no access via localhost server..

http://serverip




create table..that is not created...

go to "security group" to open this port to connect ec2 instance..
select "inbound rules"
select--edit inbound rules..
add rule and select security group of ec2 instance to get in database


open mysql workbench
fill all...

fill public ip address

for mysql host name: go to aws rds and look for end point..copy that..
fill all from aws info to sql fill ups...
and click ok
enter u r database..

create new table (new schema)
see all info and update in .env info of database..
to do login aws ec2
ls
cd "file name"
ls
ls -la
npm start  --not working error
sudo su
npm i
vi .env   --to edit the info of db 
click i  --to edit                         to exit--click "esc"



save and exit---- ":wq"                          ---:q-->exit without saving
check --> vi .env
and exit--> :q

source .env
echo $DB_USERNAME
echo $DB_NAME

npm start



testing this in web page copied from network.. ...http://localhost:3000/expense/getExpense?page=1&limit=3
show in web when run -->{'success':false}
shows success is false because jwt not..(same should show on server when u hit url)


in the same should show on server also...


copy open address in ec2 instance..
Public IPv4 address--localhost

run using ip address  of ec2 instance like below..

http://localhost:3000/expense/getExpense?page=1&limit=3

it will simply running and running...
because u not opened the port..port not accessiable
in the security grp u not opened this port...outside world to access..

the accessiable is port 22 that is for ssh--->localhost:22
it doesnt return anything because ssh..ssh for connecting servers..


ec2 instance: go to security grp and edit bount rules..

add rule:
custom tcp  3000  anywhere 0.0.0.0/0 -->anyone anywhere...


run in web-->localhost:3000
something started working -->shows  ---{'success':false}
now showing like when copied link from network 

now both link working:

http://localhost:3000/expense/getExpense?page=1&limit=3
http://localhost:3000/expense/getExpense?page=1&limit=3


now the backend is opened and 3000 is accesible

to connect frontend -->change- localhost -->localhost
all frontend will cahnge...


now run -->login or sign page and create user and login..

after login u will expense page ...and check network tab---
it will hit --Request URL: http://localhost:3000/expense/getExpense?page=1&limit=3
ip address it is hitting..

add expense-->that also hitting same:
Request URL: http://localhost:3000/expense/addExpense


this is how depoly ur application...and use it with frontend

process:

u r laptop via ssh --> ec2 instance--> from that u r getting into DB via password and username..
now the host is db host...not localhost
and it running on this endpoint..private endpoint...db not allowed accesible outside..



linux command:

pwd   --> to check directory of present..
sudo su  --> for root user..
ls -->check which floder had (not opening the floder.)
cd "floder name" --> to open floder..                      to copy--- ctrl+ shift+ c
                                                        to paste  -- right click mouse.
ls -la       ---- to look all private .files
mkdir  "new file name"
rm -rf "file name to delete"
vi .env                 -- vi its a editor without gui
git branch -a             --  to select which branch ...u had lot of branch in github
git checkout "(file name)"   --which u want open select
to insert click  --  i 
source .env                 -- to initalize all these variables..these varaibles in the terminal...initaial its empty..
echo $DB_USERNAME                            -- to print command value
echo $DB_NAME                           ...initializing all the variables in terminal...


RDS for creating database separte:

name: expenseAWS
user name: vinayuser






vt -09....step 9 Frontend Deployment to AWS



-- signed up on aws- credit/ debit card..
--aws free tier..
--backend ready- move all the secrets to the .env file..
--aws--u have to go buy a server..                                     --doing now this..
--configuring u r server(
    install node,
    sql server,
    git
)
--git u r code from github, clone it..
--running u r sql server on a different server..
--ec2 connected successfully to sql server..
--mysql workbench also connected to the DB..
--run the backend and opened the port 3000..
-- we would try to test it now from the Frontend..
--deployment the frontend to the cloud..

   -Integrate it with node js.....(many ways to deploy the frontend...here we integrate node.js)

  rgt now Backend -> sends json response when u hit the right route which u have defined

   ->send the frontend from the other routes.../Login/login.html


copy all frontend in 1 floder..


write-->app.js() 

upload all to git 
login to ec2 and clone
cd "project filefilename"
ls -la
git status
vi .env             //copy everything and keep it some where..
git branch -a
git fetch -a             //if error  do -- sudo su...and do-- git fetch -a

git checkout "projectfilename"
git pull origin "projectfilename"
vi .env                // check all there

cd "frontend"
ls
cd ../
npm start                  //-- got error  already running..



run the npm start in vs code and kill the terminal ...
and check http://localhost:3000/Login/login.html              // it will not work 



kill the terninal in aws terminal:

lsof -i :3000
kill pid                               // find PID 
lsof -i :3000
npm start                    // it starts working

copy ec2 instance ip address and run in web like below:

http://42.34.33.117:3000/Login/login.html           // it should work login page..

sign up and login...will show expense page...add expense..
login with same cred and check added expense is there r not..it should there..




vt -10 Deploying with Process Manager PM2..


10. performance and optimisation...

  --never use npm start
  process manager - pm2
    -kill the terminal it would start work
    --seeing those logs
    -status
    -- configure pm2 to restart node service on server restart
    --schedule a job which runs at 3am or anytime..


npm i -g pm2

pm2 start app.js


after kill the terminal...it is still working

want to see logs...

//nvm use 14
pm2 logs


status:
pm2 status

type command in aws terminal:
install pm2 in server
login to ec2 instance:
cd awscredential/
ssh -i "sharpenerdemo2.pem" ec2-user@3.84.55.5



pwd
cd expensetrackerbanckend/
npm start      ---(not work showing already running in 3000 and cant see logs also..because it is running on different terminal ..we cant see because dont had gui)

sudo su
lsof -i :3000

it will show running terminal all...
kill the one pid(process id):

run - kill "pid number"

npm i -g pm2                              // install in aws server..
sudo pm2 start app.js

check login and sign up..it should work...
http://42.34.33.117:3000/Login/login.html  all works in aws server

run- pm2 logs

to stop :   when npm was running find the port and kill it ...that was hectic..

run - pm2 stop all

after this pages not shown when run login and sign up page in web..

now start:

pm2 start app.js

check the login and sign page and run...it should work...

if u had multiple pm2 it can usefull...

pm2 stop 0    -->0 is id


if want to stop multiple processor running u can stop only single..no all processor..





vt-11... What is Nginx and installing it...




this port is exposed and secured

http: 80
https: 443 

3000 is not secured...--> local host was running in 3000 
if tomarrow i want run on 8000-> then i should expose 8000 ports
if tomarrow i want run on 9000-> then i should expose 9000 ports


Nginx--> port 80, port 443 -> reverse proxy to localhost:3000

3.84.55.2-->server ip...default port is 80 for http..
by default whenever u do an   http request...means u hitting port 80....
shown or display -->3.84.55.2  but it looks like...3.84.55.2:80


install Nginx:

sudo amazon-linux-extras list | grep   nginx

sudo amazon-linux-extras enable nginx1

sudo yum clean metadata
sudo yum -y install nginx
nginx -v


2 steps--
--installing Nginx package
--configure Nginx -> port 80 what should happen...-->reverse proxy to localhost:3000..


nignx server is listing on port 80...whenever request comes it is rerouting to  localhost:3000

in aws server ---ls   // in home -->ec2-user@ip
select--> cd  "etc"
ls

not found lets see other session..


copy paste code from medium website a



vt-12...Going Live with Nginx and Understanding conf files...


in aws server : run 

-->(reverse-i-search)`sy':systemctl status nginx

u can see it is running --> active(running)..


in the nginx config

whenever traffic comes to port 80-> divert it to some other port and get the response from there..

assignment total points ->7 days--> average students..

2100->300

aws server:

pwd
cd../
ls
cd../
ls
select " cd etc"
ls
cd nginx/
ls
sudo service nginx restart
systemctl status nginx      (using "nginx.conf") it will compile and excute..

 vi nginx.conf


 go to ec2 instance and open port 80...rgt now--> u opened port :22 to enter the server..and 3000--> we opened to test our application..
 add rule: select "HTTP" and select 0.0.0.0/0

 and run in web --> 3.84.55.2
 u will get  niginx page -> welcome

copy nginx path and run when open port 80 in ec2 instance..  vi /usr/share/nginx/html
:q

cd /usr/share/nginx/html
ls
u will get all inside files..
sudo vi index.html
i->insert to edit..<p> this is the default for sharpener nginx
to save-->esc :wq!  --> cant edit because not super user..(!-> forcing)


:q! --> to clear and come back..

restart:
(reverse-i-search)`res`:sudo service nginx restart ... now running on port 80 with edited

shift +C
cd ~(go back to home)
pwd
cd ../../etc/nginx/



i want 3.84.55.5:3000--i want this to be serve from this port..3.84.55.5/
we should serve login page...so we should update nginx config

vi nginx.conf

esc :q

cd conf.d/
ls                  (we dont had any file when opened so create one..)
sudo vi expensetracker.conf      

copy code from medium for listen to port 80...below copy this..



server {
   listen         80 default_server;
   listen         [::]:80 default_server;
   server_name    localhost;
   root           /usr/share/nginx/html;
location / {
       proxy_pass http://127.0.0.1:3000;
       proxy_http_version 1.1;
       proxy_set_header Upgrade $http_upgrade;
       proxy_set_header Connection 'upgrade';
       proxy_set_header Host $host;
       proxy_cache_bypass $http_upgrade;
   }
}







esc :wq!   (saving code..)
(reverse-i-search)`res`:sudo service nginx restart   --->to reload because new code added..
systemctl status nginx          (u will see active running..)


soo done with config nginx to nodejs...
u can look at thier link...there is no :3000...before it was there...
check all login add expense delete..it will work...---> 3.84.55.5/expensetracker/index.html

http is not secure...u can add https in niginx..u can look in--> cd niginx.conf


vt-13...What is IP Adress and what happens when you switch off your AWS server?

when u run any instance on aws
  --IP address -default would be dynamic
  --different -> new ipaddress

  aws says ipaddress

  static ip address


  in aws u want create elastic and associate and when reset it will not reset but in azure it will give different ip address everytime reset..

elastic ip address: search in aws
 select "allocate ip address"..
  fill all
  allcote click..


in elastic ip address which created...
select "associate elastic ip address"
choose u r instance..
enter user private address..
dont tick last checkbox..
click associate..




  go back to ec2 instance..

and select running instance and see the public ip ..."public IPv4 address"..
 and switch off and on and see ip address is same.."public IPv4 address"




  to create new dns with name namecheap.com
DNS--namecheap

  xubair.yavtechnology.com--> 168.63.234.14.80 

xubair.yavtechnology,com -> hit DNS -->will which server or ip Address..and then it will pick from there ip adrress and run......





vt-14...What are Load balancers used for


server 1--> 100% - it starts hanging...
u should increase server (ram) when it reaches capacity..8 gb ram to 16 gb ram..
the load will drop to 50% 
server 1(8gb -16gb)--> 50% load..
server 1(32 gb)--> 100% ---then it should create another server 2
server 2 (32 gb)


whenever request --> re1 1 ....req 100......(this request sent to server 1 and server 2 when decision is made by load balancer..)









CICD...



vt 1...What is CICD and Jenkins?



whenever u make any small change..
-push it to git      //local to git
-ssh into server
-pull from git....// not clone git...its already there..u need to push which u updated..
-pm2 start app.js or npm start..whatever..


what we want is automatic deployment when i push my code to git (cicd pipelines..)

 -Jenkins..
 u can pause and give id and tell to jenkins to deploy..





// when updated git push and login to aws..  this is normal deploy to aws...

cd "project name"
git branch
sudo su
git pull origin "projectname"..
pm2 stop all
pm2 start app.js
pm2 logs


run in web --> login page..

and see the logs in aws terminal..






vt 2...Installing Jenkins and accessing Jenkins UI..


what we want is automatic deployment when i push my code to git (cicd pipelines..)

-install Jenkins..
-how to configure jenkins (UI)


install jenkins in aws ...

go to u r project ...-->ExpenseTrackerBackend..

-sudo su                   // ctrl + d -->exit-- is the coming out of the super user..
-sudo yum update -y
-sudo wget -0 /etc/yum.repos.d/jenkins.repo \
 https://pkg.jenkins.io/redhat-stable/jenkins.repo

 -sudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key
 -sudo yum upgrade
   y
- sudo amazon-linux-extras install java-openjdk11 -y
-sudo yum install jenkins -y                           // u will get error...
-sudo amazon-linux-extras install epel -y
-sudo yum install jenkins -y 
-sudo systemctl enable jenkins
-sudo systemctl start jenkins
-sudo systemctl status jenkins
   jenkins is running now ..u can see it is active..




to access UI of jenkins...
-hit 8080 port with ip address of which u running...and open the port 8080 in aws securitygroup..
 42.34.33.117:8080

 add rule:

 custom tcp  8080 0.0.0.0/0(anywhere)..

 run  42.34.33.117:8080
 in aws server or where u installed jenkins:
 sudo vi "copy from which shows path in ui of jenkins"  ..for password..





 vt-3....Configure Jenkins with Git Git creds...


 
what we want is automatic deployment when i push my code to git (cicd pipelines..)

-install Jenkins..
-how to configure jenkins (UI)
    -configuring git so that jenkinscan read from (give git creds)
    - which repository u want jenkins to look at 
    -which branch
    -jenkins would store wheather it pulls from github , so u need to configure where do u want to store..
    -need to configure what commands to run ->npm i
    -whatever anything in ur repo/branch is changed , rerun everything..




login jenkins using password..

select "install suggested plugins"

fill all - inforamation  
save that http addres they gave,,,


next add git extension so need credential plugins..:

select manage jenkins
select manage plugins
search "credentials"          //it is already there..

go to dashboard..
select manage jenkins
select manage credential
select "jenkins"            //stores scoped to jenkins    "system"
select "global credential (unrestricted)"
add credential                                       // scope - global
add git email and password..


go to home jenkins
add items
enter name and click ok
select "git"  select "git credential" urs and copy "repo url" and paste..
enter which "branch" or create new branch.."cicddeploy"
create "new branch" which same name like normal git bash or vs code terminal..make some changes in code..
and commit
and push code to branch

add name branch to jenkins branch fill ups..
and "save"

click "build now"



vt-4...Configure Jenkins UI to pull from Git...

to know path --click--"console output"...and see 
and check that path in aws server..


whenever u make any small change..
 -push it to git
 -ssh into server
 -pull from git
 -npm i
 -pm2 start app.js or npm start





-install Jenkins..
-how to configure jenkins (UI)
   - we had to put a password
   -install all the recommeded plugins
   -we also set up our username and password
   -when u used to git clone, specify username and password and specify which repository u want to clone..






vt-5...Running commands automatically after importing code from git via Jenkins...   



in aws:

stop pm2:  
sudo pm2 stop all
in jenkins click: "build now"
check it is working web..

go to aws:
sudo pm2 status


if its still running...lets kill that..

lsof -i :3000
kill "id"
lsof -i :3000    // now check it is there anything running..


check in web by running...like:..3.84.55.66:300/Login/login.html

and it should not work..

in jenkins:
again : "build now" 

check in web.. confirm not working.

lets build automatic:

in aws server:

sudo npm i                // u can do this if fails..: sudo npm install  --unsafe-perm=true --allow-root 

npm start

u will get sequelize error database credential issue...and to escape.. press "ctrl+c"

open .env->  -- vi .env
                cd ~                           //root directory...-->/home/ec2-user 


                open project expense ---> which u upladed aws database cred in .env
                open .env 
                aopy and paste that details in vs code .env 
                and push and commit the code
                and push to branch "cicddeployment" in terminal vs code

 go back workspace(jenkins):

 first-- "build now"
 go to tick mark...select ...console output..
 u will find path..
 in aws server: paste that path----> cd "path"
 open env--> cd .env

go to jenkins: "build now"

now changes will show aws .env file..."cd .env"
npm start                                               // if gets error-->kill terminal...and check pm2 running stop that also by sudo...and check running other...
pm2 start app.js

                                                         // if still running stop by sudo pm2

go to jenkins: in u r project        // to add commands in jenkins..
Configure
add build: excute shell
add all commands of list and save..                 // list of commands..--> sudo npm install --unsafe-perm=true --allow-root
build now...                                                             -->sudo pm2 stop all
                                                                         -->pm2 start app.js

if error occurs do below in aws:

sudo visudo
press "i" insert
"jenkins ALL=(ALL) NOPASSWD: ALL"
:wq

go to jenkins:
 build now 

 again error occurs:
 in aws do -- pm2 stop all
pm2 start app.js

go to jenkins:
 build now 

 again error occurs:

 check commons of list added..it is sudo

// list of commands..--> sudo npm install --unsafe-perm=true --allow-root
                                          -->sudo pm2 stop all
                                          -->pm2 start app.js


run in web...3.78.55.5:3000/Login/login.html


stop the pm2 in aws--> pm2 stop all..
and run in web..it is stopped working...
now go to jenkins and "build now"
it should work...

if error occures:

pm2 status
lsof -i :3000
pm2 start app.js
lsof -i :3000


run in web...3.78.55.5:3000/Login/login.html

it should work..

go to jenkins: 
Configure
build ...check all the list of commands below :
                                          -->sudo npm install --unsafe-perm=true --allow-root
                                          -->sudo pm2 stop all
                                          -->sudo pm2 start app.js

save it
buld now


run in web...3.78.55.5:3000/Login/login.html
it should work..

 in aws do --
 --> pm2 stop all
 -->pm2 status
-->sudo pm2 status                  //if anything running super user or another user check and stop..
---> sudo pm2 stop all


go to jenkins:
buld now

now run in web...3.78.55.5:3000/Login/login.html

it will  work..



to automate:
cicd pipelines...
-so jenkins should automatically watch for new builds..
-automatically build it..                            // when changes made in vs code and push to git.. it will do automatically all things..








vt--6...Git push deploys your code directly to AWS....


to automate :

go to jenkins:
configure
build triggers
select-- poll SCM                      //source code manager..SCM
 put *****                      // corntab guru   for trigger

save it..



now do new code push when changed..

-vs code made some changes in code...
push 
commit 
in terminal vs code...--> git push origin cicddeployment

watch in jenkins...it will do automatically "build now".....           // u can see git polling log... 
